{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1943a3f3-de9c-46bd-844b-6d81e10105b5",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f4b274-933c-4a9e-916e-0d6655cfc730",
   "metadata": {},
   "source": [
    "$\\newcommand{\\b}[1]{\\mathbf{#1}} \\newcommand{\\c}[1]{\\mathcal{#1}}$\n",
    "## 1. Introduction\n",
    "\n",
    "Logistic Regression is a classification model that classifies whether a particular datapoint belongs to a class or not. Logistic Regression models the conditional densities ($P(\\b{x}|\\c{C}_1)$) and the priors ($P(\\c{C}_1)$) and uses them to find posterior probabilities $P(\\c{C}_1|\\b{x})$\n",
    "\n",
    "From Bayes' Rule:\n",
    "$$\\begin{align}\n",
    "P(\\c{C}_1|\\b{x}) &= \\frac{P(\\b{x}|\\c{C}_1)P(\\c{C}_1)}{P(\\b{x}|\\c{C}_1)P(\\c{C}_1) + P(\\b{x}|\\c{C}_2)P(\\c{C}_2)} \\\\\n",
    "&= \\frac{1}{1 + e^{-a}} \\\\\n",
    "\\text{where } a &= \\ln \\left( \\frac{P(\\b{x}|\\c{C}_1)P(\\c{C}_1)}{P(\\b{x}|\\c{C}_2)P(\\c{C}_2)} \\right)\n",
    "\\end{align}$$\n",
    "\n",
    "Note how this models $P(\\c{C}_1|\\b{x})$ as a sigmoid function. The inverse of the sigmoid is the logit, and represents the log of the ratio of probabilities\n",
    "\n",
    "For more than two classes, the sigmoid function changes to a softmax function\n",
    "$$\\begin{align}\n",
    "P(\\c{C}_k|\\b{x}) &= \\frac{P(\\b{x}|\\c{C}_k)P(\\c{C}_k)}{\\sum_i P(\\b{x}|\\c{C}_i)P(\\c{C}_i)} \\\\\n",
    "&= \\frac{e^{a_k}}{\\sum_i e^{a_i}} \\\\\n",
    "\\text{where } a_i &= \\ln \\left( P(\\b{x}|\\c{C}_k)P(\\c{C}_k) \\right)\n",
    "\\end{align}$$\n",
    "\n",
    "### 1.1. Gaussian Class-Conditional Density\n",
    "\n",
    "Let's take the simple case of two groups which have a gaussian distribution of the class-conditional density, with the same covariance matrix\n",
    "$$\\begin{align}\n",
    "P(\\c{C}_k|\\b{x}) &= \\frac{1}{(2\\pi)^{D/2}|\\b{\\Sigma}|^{1/2}} \\exp \\left\\{ -\\frac{1}{2}(\\b{x} - \\b{\\mu}_k)^T \\b{\\Sigma}^{-1} (\\b{x} - \\b{\\mu}_k) \\right\\}\n",
    "\\end{align}$$\n",
    "\n",
    "plugging this into $a$'s equation gives us \n",
    "\n",
    "$$\\begin{align}\n",
    "a &= -\\frac{1}{2}\\left( (\\b{x} - \\b{\\mu}_1)^T \\b{\\Sigma}^{-1} (\\b{x} - \\b{\\mu}_1) \\right) + \\frac{1}{2}\\left( (\\b{x} - \\b{\\mu}_2)^T \\b{\\Sigma}^{-1} (\\b{x} - \\b{\\mu}_2) \\right) + \\ln \\frac{P(\\c{C}_1)}{P(\\c{C}_2)}\n",
    "\\end{align}$$\n",
    "\n",
    "Note that \n",
    "1. $\\b{\\Sigma}$ is symmetric, hence $\\b{\\Sigma}^{-1}$ is symmetric as well\n",
    "2. Hence, $\\b{x}^T \\b{\\Sigma}^{-1} \\b{\\mu}_i = \\b{\\mu}_i^T \\b{\\Sigma}^{-1} \\b{x}$\n",
    "\n",
    "<sub>(this was not mentioned in bishop, thought it might help)</sub>\n",
    "\n",
    "This gives us\n",
    "$$a = \\left( \\b{\\Sigma}^{-1}(\\b{\\mu}_1 - \\b{\\mu}_2)\\right)^T\\b{x} + \\frac{1}{2}\\left( \\b{\\mu}_1^T\\b{\\Sigma}^{-1}\\b{\\mu}_1 + \\b{\\mu}_2^T\\b{\\Sigma}^{-1}\\b{\\mu}_2 \\right) + \\ln \\frac{P(\\c{C}_1)}{P(\\c{C}_2)}$$\n",
    "\n",
    "This is nicely visualized here:\n",
    "\n",
    "![sing](single_boundary.png)\n",
    "\n",
    "Note that there are no quadratic terms here: they cancel out because of the same covariance matrix. If the covariance matrices were different, we would have a $\\frac{1}{2} \\left( \\b{x}^T (\\b{\\Sigma}_2^{-1} - \\b{\\Sigma}_1^{-1}) \\b{x} \\right)$ term as well, giving us a quadratic decision boundary, which would look something like this \n",
    "\n",
    "![mult](multiple_boundary.png)\n",
    "\n",
    "(pictures taken from bishop. The red and green distributions have the same covariance matrix and hence a linear decision boundary, whereas the blue one has a quadratic decision boundary)\n",
    "\n",
    "\n",
    "### 1.2. MLE estimation\n",
    "\n",
    "\n",
    "\n",
    "### 1.3. General Linear Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471bb06c-fa6e-42b1-9aa2-e6999988c65e",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression with 2 Classes\n",
    "\n",
    "We use a processed version of the [Cleveland Heart Disease dataset](https://archive.ics.uci.edu/ml/datasets/heart+disease) for this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f417fea-9cff-4236-badd-e3295da71f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Sensei/.pyenv/versions/3.9.0/lib/python3.9/site-packages/pandas/compat/__init__.py:97: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8022ad94-d17a-46d0-95de-fd1dd0d1e37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('../data/heart_disease/cleveland.csv').set_index('SNO')\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('num',axis=1),df['num'],stratify=df['num'],test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65463017-9d9f-471b-9ba9-8a094e32d328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
